---
title: 'LTER Variability: The Pipeline'
author: "Tom Miller"
date: "September 20, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
library(knitr)
library(dplyr)
library(tidyverse)
library(devtools) #needed to download prism from github
library(reshape2) ##melting dataframes
library(raster) ##working with raster data
library(sp) ##manipulationg spatial data
#install_github(repo = "prism", username = "ropensci")
library(prism) ##prism data access
library(rstan)
library(SPEI)
library(mgcv)
library(scales)
```
## Set-up
popler was recently published on ROpenSci, so we have a final legit version to install. You will want to uncomment the installation code and run this chunk. But then recomment it since it takes a little while to run and this only needs to be done once. 
```{r popler_install}
#install.packages("devtools")
#if(!require(devtools, quietly = TRUE)) {
#  install.packages(devtools)
#}
#devtools::install_github('ropensci/popler')
library(popler)
```
We will need prism data for calculating SPEI at each site (this file was created by Bene, we'll need to get that code up on github), and eventually we will want a csv that provides the census month of each study. For reasons we will discuss, we currently do not have such a table and populating it will be a little tricky. For now, this is just a place-holder.
```{r read_files}
prism <- read_csv("prismdata.csv") 
#census_months <- read_csv("census_months.csv")
```

## Fully worked example, step-by-step
This document will walk through the pipeline using an example data set, the herons from VCR. popler identifies studies by their metadata key. This one is 88. To use this code with a new data set, just replace 88 with your metadata key. Here we identify the target study and pull some important metadata about it. 
```{r metadata}
k <- 88
## extract popler project data and metadata
command <- paste0('pplr_browse( proj_metadata_key==',k,', full_tbl = T)')
metadat<-parse(n=1, text=command) %>% eval
  ## diagnose the data type
  type <- metadat$datatype
  ## break out of function if datatype is individual or basal cover
  ##if(type=="individual" | type=="basal_cover"){return("Non-desired data type")}
```
Next we download the data and implement a few important manipulations that will allow us to fit random effects for the interaction of spatial replication levels. (This chunk is set to eval=F because get_data can take a while.)
```{r get_data}
## get data and combine spatial rep info
n_spat_levels <- metadat$n_spat_levs
dat <- pplr_get_data(metadat,cov_unpack = T) %>% 
    as.data.frame %>% 
    mutate(n_spat_levels = n_spat_levels) %>% 
    mutate(ran_effect = ifelse(n_spat_levels==1,spatial_replication_level_1,
                               ifelse(n_spat_levels==2,interaction(spatial_replication_level_1,spatial_replication_level_2),
                                      ifelse(n_spat_levels==3,interaction(spatial_replication_level_1,spatial_replication_level_2,spatial_replication_level_3),
                                             interaction(spatial_replication_level_1,spatial_replication_level_2,spatial_replication_level_3,spatial_replication_level_4))))) %>% 
    filter(!is.na(abundance_observation))
```
Note that we are filtering out NAs. We were not comfortable with the assumption that NAs are zeros (though we suspect in some cases they are), so we are simply sticking to the data exactly as the originator reported them. 

Some studies use species codes and some use actual species names. For the latter, we are just calling the name a "code" so we will consistently identify species identity based on sppcode.
```{r sppcode}
  if("sppcode"%in%colnames(dat)==FALSE) {colnames(dat)[colnames(dat)=="species"]<-"sppcode"}
```
A few other miscellany items to take care of. First, we decided to drop species that had zero abundance in any year of the study. This means we are effectively considering common species that are consistently observed (and we should consider what biases this may introduce in the results). Second, if the data are structured (meaning different abundance observations for different size classes, life stages, etc.) then we will sum over structure classes (this code is not written yet and does not apply to the heron data). Third, cover data are sometimes reported from 0 to 100 and sometimes from 0 to 1. Here we scale them all to 100. 
```{r misc}
drop_rare <- dat %>% 
    group_by(sppcode,year) %>% 
    summarise(total_obs_per_year = sum(abundance_observation))%>% 
    filter(total_obs_per_year == 0)%>% 
    summarise(unique(sppcode))
newdat <- dat[(dat$sppcode%in%drop_rare$sppcode)==FALSE,] 
  
if(metadat$structured_data=="yes"){}#do something
  
if(type=="cover")
  {
    q<-quantile(newdat$abundance_observation)
    if(q[4]<1)
    {
      newdat$abundance_observation<-newdat$abundance_observation*100
      newdat<-newdat[newdat$abundance_observation<=100,]
    }
  }
```


## Statistical model for abundance by year
We are fitting a relatively simple model for the average abundance in each year for each species, with spatial replicates as a random effect. For count data (like the herons), the number of individuals of species $i$ in spatial replicate $j$ and year $t$ was modeled as a negative binomial process:
$y_{i,j,t} \sim NegBin(\mu_{i,j,t},\phi_{i})$
$log(\mu_{i,j,t}) = a_{i,t} + \epsilon_{j}$
$\epsilon_{j} \sim N(0,\sigma^{2})$
The expected value is $\mu_{i,j,t}$ and each species gets its own overdispersion term $\phi_{i}$. Note that the random effect for spatial replicate ($\epsilon_{j}$) is shared across species. Thus, we are assuming that good and bad sites are equally good and bad for all species. For other data types, the model is conceptually identical but uses a different distribution. The pipeline code is set up to distinguish which data type you are working with. 

Under this model, the mean abundance of species $i$ in year $t$ is given by $e^{a_{i,t}}$ and the population growth rate is given by $\lambda_{i,t}=\frac{e^{a_{i,t}}}{e^{a_{i,t-1}}}$. The Stan model calculates $\lambda_{i,t}$ as well as $r_{i,t} = log(\lambda_{i,t})$ as derived quantities with full posterior distributions. In theory, $\lambda_{i,t}$ and $r_{i,t}$ provide redundant information. We are asking whether $\lambda_{i,t}$ responds linearly to climate variation, in which case $r_{i,t}$ should -- again, *in theory*, respond non-linearly with a negative second derivative. For example:
```{r lambda_r}
clim<-seq(0,10,length.out = 50)
lambda_clim <- function(x,a=0.5,b=0.8){a+b*x}
par(mfrow=c(1,2))
plot(clim,lambda_clim(x=clim),type="l")
plot(clim,log(lambda_clim(x=clim)),type="l")
```
However, due to noisiness in real data, it is possible that we could find that both $\lambda$ and $r$ respond linearly to climate variation. We are not sure what we will do in this case but we are calculating both metrics on the front end so that we can deal with this later if it arises.

Now prep the data for the Stan model and run. 
```{r stan_run, eval=F}
  #prep data for stan
  datalist<-list(
    n=nrow(newdat),
    nyear=length(unique(as.factor(newdat$year))),
    nrep=length(unique(as.factor(newdat$ran_effect))),
    nsp=length(unique(as.factor(newdat$sppcode))),
    year=as.numeric(as.factor(as.character(newdat$year))),
    rep=as.numeric(as.factor(as.character(newdat$ran_effect))),
    sp=as.numeric(as.factor(as.character(newdat$sppcode))),
    count=newdat$abundance_observation)
  
  ## send to the appropriate JAGS model, given data type
  stan_model <- ifelse(type=="count","Bene\\count_model_Poisson.stan",
                       ifelse(type=="density","Bene\\biomass_density_model.stan",
                              ifelse(type=="biomass","Bene\\biomass_density_model.stan",
                                     "Bene\\cover_model.stan")))

## Need to round up count and cover because some entries have decimals  
if(type=="count" | type=="cover"){datalist$count<-round(datalist$count)}

  abund_fit<-stan(file=stan_model,data=datalist,iter=5000,chains=3,warmup=500)
```

Evaluate model fit.
```{r fit}
  ## Bayesian p-value
  newy<-rstan::extract(abund_fit,"newy")[[1]]
  new_mean<-apply(newy,2,mean)
  (bayes.p<-length(new_mean[new_mean>mean(newdat$abundance_observation)])/length(new_mean))
  
```


## Climate data
Now we need to prepare climate data corresponding to the abundance time series that we just fit a model to. This code is a mash-up of contributions from Bene, Linyi, Shannon, and Marion. Thanks y'all! It was a little tricky to line up the timing of climate with the timing of a transition year in the abudance data set, but this works!

There are two climate data sets created below. One corresponds just to the years included in the focal study. The other includes all the years we have available from prism (what are these years??). We will use the latter to draw inferences about climate variability beyond the observation years of the study. 

Note that census_month is typed in for the heron data. This will need to be updated for your studies, and will hopefully get populated authomatically once we finalize the census_months.csv file.
```{r climate_dat}
## climate covariate
  study_site <- metadat$lterid
  site_lat <- round(metadat$lat_lter,2)
  site_long <- round(metadat$lng_lter,2)
  study_years <- sort(unique(newdat$year)) #metadat$studystartyr:metadat$studyendyr
  census_month <- 5 #read_csv("census_months.csv") %>% 
  #filter(proj_metadata_key == k) %>% 
  #summary(unique(Census_month))
  
  climate <- prism %>% 
    dplyr::select(-X1) %>% 
    filter(LTERlocation.id == study_site,
           year %in% min(study_years):max(study_years)) %>% 
    group_by_at(vars(-value)) %>%  # group by everything other than the value column. 
    mutate(row_id=1:n()) %>% ungroup() %>%  # build group index
    spread(key = variable, value = value)%>% 
    dplyr::select(-row_id) %>%
    ##thornthwaite function does not like NAs
    filter(!is.na(tmean),
           !is.na(ppt))%>% 
    distinct() %>% 
    ##df with years and months for ppt and temp
    ## convert calendar year to transition year
    mutate(climate_year = ifelse(month >=census_month, year+1, year),
           # Compute potential evapotranspiration (PET) and climatic water balance (BAL)
           PET = thornthwaite(tmean,site_lat),
           BAL = ppt-PET) %>% 
    filter(climate_year>min(study_years) & climate_year<=max(study_years)) 
  ## climate data should start 12 months before first abundance observation
  spei12 <- spei(climate[,'BAL'], 12)
  
  ## climate data for prediction
  climate_pred <- prism %>% 
    dplyr::select(-X1) %>% 
    filter(LTERlocation.id == study_site) %>% 
    group_by_at(vars(-value)) %>%  # group by everything other than the value column. 
    mutate(row_id=1:n()) %>% ungroup() %>%  # build group index
    spread(key = variable, value = value)%>% 
    dplyr::select(-row_id) %>%
    ##thornthwaite function does not like NAs
    filter(!is.na(tmean),
           !is.na(ppt))%>% 
    distinct() %>% 
    ##df with years and months for ppt and temp
    ## convert calendar year to transition year
    mutate(climate_year = ifelse(month >=census_month, year+1, year),
           # Compute potential evapotranspiration (PET) and climatic water balance (BAL)
           PET = thornthwaite(tmean,site_lat),
           BAL = ppt-PET) %>% 
    filter(climate_year<=max(year))
    climate_pred <- climate_pred[-(1:(census_month-1)),]
    spei12_pred <- spei(climate_pred[,'BAL'], 12)
```

Now connect the fitted estimates of abundance to climate
```{r}
spp_names <- levels(as.factor(as.character(newdat$sppcode)))
r_mean <- data.frame(matrix(rstan::summary(abund_fit,"r")[[1]][,"mean"],nrow=(datalist$nyear-1),ncol=datalist$nsp,byrow = T)[(study_years[2:length(study_years)]-study_years[1:(length(study_years)-1)])==1,])
lambda_mean <- data.frame(matrix(rstan::summary(abund_fit,"lambda")[[1]][,"mean"],nrow=(datalist$nyear-1),ncol=datalist$nsp,byrow = T)[(study_years[2:length(study_years)]-study_years[1:(length(study_years)-1)])==1,])

year<-as.numeric(levels(as.factor(as.character(newdat$year))))[-1][(study_years[2:length(study_years)]-study_years[1:(length(study_years)-1)])==1]
sp<-rep(spp_names,(datalist$nyear-1))
colnames(r_mean) <- levels(as.factor(as.character(newdat$sppcode)))
r_mean$year <- year
colnames(lambda_mean) <- levels(as.factor(as.character(newdat$sppcode)))
lambda_mean$year <- year

    r_clim <- full_join(r_mean %>% 
                             gather(key="species",value="r",1:length(spp_names))%>% 
                             mutate(species=as.factor(species)),
                               tibble(SPEI = spei12$fitted[seq(from=12,to=length(spei12$fitted),by=12)],
                                      year = (min(study_years):max(study_years))[-1]),
                               by="year")%>% 
      filter(!is.na(r))
    
    ## and do the same for lambda
        lambda_clim <- full_join(lambda_mean %>% 
                             gather(key="species",value="lambda",1:length(spp_names))%>% 
                             mutate(species=as.factor(species)),
                               tibble(SPEI = spei12$fitted[seq(from=12,to=length(spei12$fitted),by=12)],
                                      year = (min(study_years):max(study_years))[-1]),
                               by="year")%>% 
      filter(!is.na(lambda))
```

Now find which species have a "significant" gam fit. The code below is very inefficient but I found the full interaction model (species as factor, interaction with the smooth term) to be difficult to work with. I also do not like the odd mash-up of Bayesian and frequentist methods. Here we exclude gams that are not significant with $\alpha=0.1$ but then go on to estimate posterior estimates for the significant ones. It's a weird approach and we should discuss. 

Also, I am fitting gams to both r and lambda to see if they differ. They do! I think r is the more theoretically defensible response variable, but we will need to discuss. 
```{r significant_gams}
spp_gam_p<-spp_gam_p_lambda<-c()
for(i in 1:length(spp_names)){
  spp_gam_p[i]<- summary(gam(r ~ s(SPEI), data=subset(r_clim,species==spp_names[i])))$s.table[4]
  spp_gam_p_lambda[i]<- summary(gam(lambda ~ s(SPEI), 
                                    data=subset(lambda_clim,species==spp_names[i])))$s.table[4]
}
tibble(species = spp_names,
       gam_pvalue_r = spp_gam_p,
       gam_pvalue_lambda = spp_gam_p_lambda)
## pull out the significant species, going with the r results
sig_spp<-spp_names[which(spp_gam_p <= 0.1)]
```

Another problem: it troubles me that we get different p values depending on whether species are fit together or separately. Compare above to:
```{r spp_together}
summary(gam(r ~ species + s(SPEI, by=species), data=r_clim))$s.table
```

This shows that only one species in this study had a "significant" relationship between r and SPEI. Here is what that looks like for the posterior mean r values. This shows a linear response.
```{r post_mean}
  gam_fit <- gam(r ~ s(SPEI), data=subset(r_clim,species==sig_spp))
  SPEI.seq<-data.frame(SPEI=rep(seq(min(r_clim$SPEI),max(r_clim$SPEI),length=100)))
  preds<-predict(gam_fit, type="terms", newdata=SPEI.seq,se.fit=TRUE)
  plot(SPEI.seq$SPEI,preds$fit,type="l",lwd=2)
  points(r_clim$SPEI[r_clim$species==sig_spp],r_clim$r[r_clim$species==sig_spp],pch=16,cex=2)

```

For that species, I will next fit a gam for each posterior sample. 
```{r, fig.align = "center", fig.height = 10, fig.width = 10, out.width = "10in"}
r_posterior <- rstan::extract(abund_fit,"r")[[1]][,(study_years[2:length(study_years)]-study_years[1:(length(study_years)-1)])==1,]

par(mfrow=c(3,3),mar=c(5,4,1,1))
## loop over species with significant mean gams
for (s in 1:length(spp_names)){
  ## here is the posterior mean fit (red is significant)
  gam_fit <- gam(r ~ s(SPEI), data=subset(r_clim,species==spp_names[s]))
  SPEI.seq<-data.frame(SPEI=rep(seq(min(r_clim$SPEI),max(r_clim$SPEI),length=100)))
  preds_mean<-predict(gam_fit, type="terms", newdata=SPEI.seq,se.fit=TRUE)
  plot(r_clim$SPEI[r_clim$species==spp_names[s]],r_clim$r[r_clim$species==spp_names[s]],
       cex.lab=2,xlab="SPEI",ylab="r",type="n",ylim=c(-4,4))
  title(main = paste("Species: ",spp_names[s]),adj=0)
  
  ## add posterior samples
  for(i in 1:500){
    df_i <- data.frame(r_posterior[i,,])
    colnames(df_i) <- spp_names#levels(as.factor(as.character(newdat$sppcode)))
    df_i$year <- year
    r_clim_i <- full_join(
      df_i %>% 
      gather(key="species",value="r",1:length(spp_names)) %>% 
      mutate(species=as.factor(species)) %>% 
      #filter(species %in% sig_spp),
      filter(species==spp_names[s]),
      tibble(SPEI = spei12$fitted[seq(from=12,to=length(spei12$fitted),by=12)],
                               year = (min(study_years):max(study_years))[-1]),
      by="year")%>% 
      filter(!is.na(r))
    
  gam_fit_i <- gam(r ~ s(SPEI), data=subset(r_clim_i,species==spp_names[s]))
  preds<-predict(gam_fit_i, type="terms", newdata=SPEI.seq,se.fit=TRUE)
  lines(SPEI.seq$SPEI,preds$fit,type="l",col=alpha(ifelse(summary(gam_fit)$s.table[4]<0.1,"red","black"),0.1))
  points(r_clim_i$SPEI[r_clim_i$species==spp_names[s]],
         r_clim_i$r[r_clim_i$species==spp_names[s]],pch=".",cex=3,col=alpha("grey40",0.1))
  }
  lines(SPEI.seq$SPEI,preds_mean$fit,type="l",lwd=4,
        col=ifelse(summary(gam_fit)$s.table[4]<0.1,"red","black"))
  points(r_clim$SPEI[r_clim$species==spp_names[s]],r_clim$r[r_clim$species==spp_names[s]],
       pch=16,cex=2)
}
```

```{r}

  #for(i in 1:abund_fit@sim$iter){
  #just 100 posterior samples for now
  for(i in 1:100){
    df_i <- data.frame(r_posterior[i,,])
    colnames(df_i) <- spp_names#levels(as.factor(as.character(newdat$sppcode)))
    df_i$year <- year
    r_clim_i <- full_join(
      df_i %>% 
      gather(key="species",value="r",1:length(spp_names)) %>% 
      mutate(species=as.factor(species)) %>% 
      filter(species %in% sig_spp),
      tibble(SPEI = spei12$fitted[seq(from=12,to=length(spei12$fitted),by=12)],
                               year = (min(study_years):max(study_years))[-1]),
      by="year")%>% 
      filter(!is.na(r))
    
  gam_fit_i <- gam(r ~ s(SPEI), data=subset(r_clim_i,species==sig_spp[s]))
  preds<-predict(gam_fit_i, type="terms", newdata=SPEI.seq,se.fit=TRUE)
  lines(SPEI.seq$SPEI,preds$fit,type="l",col=alpha("black",0.5))
  points(r_clim_i$SPEI[r_clim_i$species==sig_spp[s]],r_clim_i$r[r_clim_i$species==sig_spp[s]],pch=16,col=alpha("red",0.05))

  }
```


Fit gam to the posterior mean r-climate relationship.
```{r}
    #gam_fit_mean <- gam(lambda ~ species-1 + s(SPEI, by=species), data=r_clim)
    #having trouble with species as an interaction factor, going with a single species for now
    gam_fit_mean <- gam(lambda ~ s(SPEI), data=subset(r_clim,species=="BC"))
    plot(gam_fit_mean,residuals = T)
    summary(gam_fit_mean)
    
    ## create a new data frame for predicting the gam
    n_SPEI <- 100
    #SPEI.seq<-data.frame(species=rep(unique(r_clim$species),each=n_SPEI),
    #                     SPEI=rep(seq(min(r_clim$SPEI),max(r_clim$SPEI),length=n_SPEI),
    #                              times=length(unique(r_clim$species))))
    SPEI.seq<-data.frame(SPEI=rep(seq(min(r_clim$SPEI),max(r_clim$SPEI),length=n_SPEI)))
    preds<-predict(gam_fit_mean, type="terms", newdata=SPEI.seq,se.fit=TRUE)
    
    plot(SPEI.seq$SPEI,preds$fit,type="l",lwd=2)
    points(r_clim$SPEI[r_clim$species=="BC"],r_clim$r[r_clim$species=="BC"],pch=16,cex=2)
```
Now calculate the key quantity that we are interested in: $V = \bar{f(x)} - f(\bar{x})$, first using the entire climate record 1915-2018 ($V_{all}$):
```{r V_all}
SPEI_allyrs = tibble(SPEI = spei12_pred$fitted[seq(from=12,to=length(spei12_pred$fitted),by=12)],
                   year = (min(climate_pred$year):max(climate_pred$year))[-1])
SPEI_mean = data.frame(mean(SPEI_allyrs$SPEI));names(SPEI_mean)[1]="SPEI"

  
V = mean(predict(gam_fit_mean, type="terms", newdata=SPEI_allyrs,se.fit=TRUE)$fit) - 
  predict(gam_fit_mean, type="terms", newdata=SPEI_mean,se.fit=TRUE)$fit

plot(SPEI.seq$SPEI,preds$fit,type="l",lwd=2)
points(r_clim$SPEI[r_clim$species=="BC"],r_clim$r[r_clim$species=="BC"],pch=16,cex=2)
points(SPEI_mean$SPEI,predict(gam_fit_mean, type="terms", newdata=SPEI_mean,se.fit=TRUE)$fit,col="red",cex=3) 
points(SPEI_mean$SPEI,mean(predict(gam_fit_mean, type="terms", newdata=SPEI_allyrs,se.fit=TRUE)$fit),col="red",cex=3,pch=16)       

```

Now calculate as above but in a 30-year sliding window
```{r}
hist(SPEI_allyrs$SPEI)
plot(SPEI_allyrs$year,SPEI_allyrs$SPEI,type="l")
```

